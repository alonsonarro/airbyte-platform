VERSION=dev

# Airbyte Internal Job Database, see https://docs.airbyte.io/operator-guides/configuring-airbyte-db
DATABASE_USER=docker
DATABASE_PASSWORD=docker
DATABASE_HOST=db
DATABASE_PORT=5432
DATABASE_DB=airbyte
# translate manually DATABASE_URL=jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT/${DATABASE_DB}
DATABASE_URL=jdbc:postgresql://db:5432/airbyte

# Cloud database connection info
CLOUD_DATABASE_URL=jdbc:postgresql://db:5432/airbyte
CLOUD_DATABASE_USER=docker
CLOUD_DATABASE_PASSWORD=docker

# Airbyte Internal Config Database, default to reuse the Job Database when they are empty
# Usually you do not need to set them; they are explicitly left empty to mute docker compose warnings
CONFIG_DATABASE_USER=
CONFIG_DATABASE_PASSWORD=
CONFIG_DATABASE_URL=

# When using the airbyte-db via default docker image:
CONFIG_ROOT=/data
DATA_DOCKER_MOUNT=airbyte_data
DB_DOCKER_MOUNT=airbyte_db

# Temporal.io worker configuration
TEMPORAL_HOST=airbyte-temporal:7233

# Workspace storage for running jobs (logs, etc)
WORKSPACE_ROOT=/tmp/workspace
WORKSPACE_DOCKER_MOUNT=airbyte_workspace

# Local mount to access local files from filesystem
# todo (cgardens) - when we are mount raw directories instead of named volumes, *_DOCKER_MOUNT must
# be the same as *_ROOT.
# Issue: https://github.com/airbytehq/airbyte/issues/578
LOCAL_ROOT=/tmp/airbyte_local
LOCAL_DOCKER_MOUNT=/tmp/airbyte_local
# todo (cgardens) - hack to handle behavior change in docker compose. *_PARENT directories MUST
# already exist on the host filesystem and MUST be parents of *_ROOT.
# Issue: https://github.com/airbytehq/airbyte/issues/577
HACK_LOCAL_ROOT_PARENT=/tmp

# Cloud Service Configs. Specifics how the api and cloud servers talk to each other.
# These should match the docker-compose file.
CLOUD_SERVER_SVC_HOST=cloud-server
CLOUD_SERVER_SVC_PORT=8002
API_SERVER_SVC_HOST=airbyte-server
API_SERVER_SVC_PORT=8001

# Miscellaneous
TRACKING_STRATEGY=segment
DEPLOYMENT_MODE=CLOUD
WEBAPP_URL=http://localhost:8000/
API_URL=/api/v1/
INTERNAL_API_HOST=airbyte-server:8001
LOG_LEVEL=INFO

# Cloud log backups. Don't use this unless you know what you're doing. Mainly for Airbyte devs.
# If you just want to capture Docker logs, you probably want to use something like this instead:
# https://docs.docker.com/config/containers/logging/configure/
S3_LOG_BUCKET=
S3_LOG_BUCKET_REGION=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
S3_MINIO_ENDPOINT=
S3_PATH_STYLE_ACCESS=

GCS_LOG_BUCKET=

# Docker Resource Limits
JOB_MAIN_CONTAINER_CPU_REQUEST=
JOB_MAIN_CONTAINER_CPU_LIMIT=
JOB_MAIN_CONTAINER_MEMORY_REQUEST=
JOB_MAIN_CONTAINER_MEMORY_LIMIT=

# Monitoring client setting
METRIC_CLIENT="datadog"
